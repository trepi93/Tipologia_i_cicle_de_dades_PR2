---
title: 'PRACTICA 2: ANÀLISI DE VOT A ESTATS UNITS'
author: "Ferran Castel i David Trepat"
date: "Gener 2024"
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 5
subtitle: "M2.951 - Tipologia i cicle de vida de les dades"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
library(dplyr)
library(corrplot)
library(ggplot2)
library(gridExtra)
if(!require("VIM")) install.packages("VIM")
library("VIM")
if(!require("formatR")) install.packages("formatR")
library("formatR")
library(tidyr)
library(knitr)
if (!requireNamespace("moments", quietly = TRUE)) {
  install.packages("moments")}
library(moments)
if (!requireNamespace("car", quietly = TRUE)) {
  install.packages("car")}
library(car)
if(!require("ggcorrplot")) install.packages("ggcorrplot");
library(ggcorrplot)
library(caret)
if (!requireNamespace("leaflet", quietly = TRUE)) {
  install.packages("leaflet")
}
if (!requireNamespace("sf", quietly = TRUE)) {
  install.packages("sf")
}
if (!requireNamespace("maps", quietly = TRUE)) {
  install.packages("maps")
}
library(sf)
library(maps)
library(leaflet)
```

# 1. Descripció del dataset

L'objectiu del present treball és estudiar **quins factors demogràfics i socioeconòmics són rellevants en les eleccions presidencials als Estats Units del 2020**, per tal de poder fer estimacions i prediccions estadístiques.

En aquest sentit, volem poder avaluar quins grups de població voten pel partit demòcrata i quins pel partit republicà, per tal de poder predir el possible resultat a cada comtat americà, i també poder validar o desmentir alguns dels mantres més usuals en política (com que la gent de raça afroamericana vota més el partit demòcrata o que la gent més adinerada acostuma a votar al partit republicà). Cal tenir en compte que per la dicotomia del sistema polític americà es fa díficil situar tant a Demòcrates com a Republicans a l'esquerra de l'aspectre polític al qual nosaltres estem més avesats, però considererem que els Demòcrates són, en general, més progressistes que els Republicans.

Els datasets escollits són els següents:

-   **county_demographics.csv:** és el dataset principal del treball. Conté dades demogràfiques i socioeconòmiques a nivell de comtat americà (un estat el composen diferents comtats). Aquest dataset conté tant dades d'edat poblacional (prefix Age), com dades de nivell educatiu (prefix Education), com dades d'ocupació (prefix Employment), com dades de distribució ètnica (prefix Ethnicities), com dades d'unitats familiars (prefix Housing), com dades d'ingressos (prefix Income), com dades poblacionals totals (prefix Population), entre moltes altres dades. Les dades són del període entre 2010 i 2019 (en el dataset figura, per cada comtat, la més recent entre totes les disponibles) i són extretes directament de l'Oficina Federal del Cens Americà.

    És el dataset més important perquè ens permet tenir una imatge real i fidedigna de la demografia i les condicions socials i econòmiques dels diferents comtats americans per tal de poder veure tendències pel que fa al vot.

    Finalment, també cal dir que si bé les eleccions que analitzarem són de 2020 (i les dades demogràfiques són de 2019), considerem que aquest dataset és suficient perquè ens mostra la imatge sociodemogràfica de la societat americana just abans de ser cridats a les urnes.

    ***Font:*** <https://www.kaggle.com/datasets/mexwell/us-country-demographics>

-   **president_county_candidate.csv**: d'aquest dataset només volem extreure el candidat que ha guanyat les eleccions presidencials americanes de 2020 per comtat, i també la diferència de vots entre tots dos candidats (variable que crearem). En aquest sentit, només prendrem les eleccions del 2020 ja que creiem que és suficient pel treball i els objectius a realitzar. Sens dubte, podríem fer un estudi més acurat, tenint en compte més períodes electorals (i també més dades demogràfiques), però creiem que potser es podria escapar dels objectius didàctics d'aquesta pràctica.

    ***Font:*** <https://www.kaggle.com/datasets/unanimad/us-election-2020>

-   **uscities.csv**: d'aquest dataset només extraurem les sigles de cada estat americà, a partir del seu nom. Ens servirà per poder unir les dades electorals al primer dataset esmentat.

    ***Font:*** <https://www.kaggle.com/datasets/louise2001/us-cities>

En l'apartat següent procedirem a fer la integració de les dades.

```{r}
# Carreguem els diferents datasets
demographics_df <- read.csv("county_demographics.csv")
elections_df <- read.csv("president_county_candidate.csv")
cities_df <- read.csv("uscities.csv")
```

# 2. Integració i selecció

## 2.1 Integració

En aquest apartat integrarem els tres datasets esmentats en l'apartat anterior per tal d'obtenir-ne un de sol que és amb el que treballarem. Per fer-ho, primer afegirem en el dataset de les dades electorals les sigles de cada estat. Posteriorment, afegirem una variable nova que capturi la diferència de vots entre Joe Biden i Donald Trump per cada comtat i, finalment, afegirem la columna de guanyadors i la de diferència de vots creada en el dataset de dades demogràfiques.

Abans de començar amb la fusió, però, volem extreure el nombre de comtats de cada dataset per veure si perdem observacions durant el procés:

```{r}
paste0("Comtats demographics.csv: ", nrow(unique(demographics_df[, c('County', 'State')])))

paste0("Comtats president_county_candidate.csv: ", nrow(unique(elections_df[, c('county', 'state')])))

```

Observem d'entrada que en el dataset d'eleccions hi ha més comtats perquè potser hi ha alguna subdivisió més a nivell electoral. Sabem que el nombre de comtats a EEUU és de 3.143 amb la qual cosa el dataset principal és més fidedigne en aquest sentit (en falten 4 que podria ser per falta de dades).

```{r}
# Extraiem del dataset cities els estats i les seves sigles

state_dict <- unique(cities_df[, c("state_name", "state_id")])

# Afegim una nova columna al dataset d'eleccions amb les sigles de l'estat

elections_df <- merge(elections_df, state_dict, by.x = 'state', by.y = 'state_name')
```

Procedim a crear la nova variable de diferència de vots entre Joe Biden i Donald Trump

```{r}
# Calculem la diferència de vots entre Joe Biden i Donald Trump
diff_votes <- elections_df %>%
  filter(candidate %in% c("Joe Biden", "Donald Trump")) %>%
  group_by(state, county) %>%
  summarize(diff_Biden_Trump = total_votes[candidate=="Joe Biden"] - total_votes[candidate=="Donald Trump"], 
            .groups = 'drop')

# Ho unim al dataset d'eleccions i ens quedem només amb els resultats del guanyador

elections_df <- left_join(elections_df, diff_votes, by=c('state', 'county'))
elections_df <- elections_df[elections_df$won=="True",]


```

Finalment, ho unim tot al dataset demographics que és amb el que treballarem

```{r}
demographics_df <- merge(demographics_df, elections_df[,c('county', 'state_id', 'party', 'diff_Biden_Trump')], 
                         by.x=c('County', 'State'), 
                         by.y = c('county', 'state_id'))

```

Tornem a veure quants estats té el dataset resultant

```{r}
paste0("Comtats demographics.csv: ", nrow(unique(demographics_df[, c('County', 'State')])))
```

Observem com s'han perdut un centenar de comtats respecte el dataset inicial. Això es pot deure a múltiples factors, essent el més usual que la transcripció del comtat no coincideixi en ambdós datasets o que el dataset de vots contingui municipis que no siguin considerats comtats. Tot i això, hem decidit procedir sense aquests en concret perquè la mostra és prou gran com per poder fer un estudi robust.

Finalment remetem a l'Annex 1 per veure les principals estadístiques del dataset.

## 2.2 Selecció de dades

A partir de la llegenda de les 46 variables inicials, decidim eliminar-ne les que conceptualment aporten menys signficat a nivell electoral o que aporten informació redundant que poden tenir impacte en el model final. Optem per aquesta opció perquè el número inicial de variables és massa extens i ens pot dificultar extreure conclusions plausibles (a més de possibles altres problemes com overfitting en models de regressió, o possible multicolinealitat en alguns casos si dues variables contenen informació semblant). Per tant, eliminarem les següents:

-   **Age.Percent.Under.5.Years**: Amb la variable *Age.Percent.Under.18.Years* ja s'obté informació rellevant del percentatge de menors en el comtat.

-   **Education.Bachelor.s.Degree.or.Higher** Ens interessa més saber el percentatge de població amb estudis obligatoris més que el percentatge d'estudis superiors.

-   **Ethnicities variables**: En tots els estats, les ètnies majoritàries són la blanca, negra i hispana, la resta són minoritàries i no les contamplarem. En alguns casos, a més, la variable només exposa el percentatge de gent que té dues ètnies, sense especificar quines. Per tant, eliminem:

    -   **Ethnicities.American.Indian.and.Alaska.Native.Alone**
    -   **Ethnicities.Two.or.More.Races**
    -   **Ethnicities.Native.Hawaiian.and.Other.Pacific.Islander.Alone**
    -   **Ethnicities.White.Alone** (aquesta compta els % de blancs incloent-hi població hispana)

-   **Miscellaneous.Foreign.Born**: El percentatge d'immigrants no és objecte d'aquest estudi ja que volem estudiar la població que té poder electoral. A més, no podem distingir els que poden votar (tenen nacionalitat) dels que no i també és possible que s'inclogui en el percentatge d'ètnia.

-   **Employment variables**: Computa dades d'ocupació i empresa per comtat. Ens interessa el nombre global d'empreses obertes més que qui les dirigeix, que considerem un fet circumstancial i molt menor. Aquests són:

    -   **Employment.Nonemployer.Establishments**
    -   **Employment.Firms.Women.Owned**
    -   **Employment.Firms.Men.Owned**
    -   **Employment.Firms.Minority.Owned**:
    -   **Employment.Firms.Nonminority.Owned**
    -   **Employment.Firms.Veteran.Owned**
    -   **Employment.Firms.Nonveteran.Owned**

```{r}
variables_to_remove <- c(
  "Age.Percent.Under.5.Years",
  "Education.Bachelor.s.Degree.or.Higher",
  "Ethnicities.Native.Hawaiian.and.Other.Pacific.Islander.Alone",
  "Ethnicities.Two.or.More.Races",
  "Ethnicities.White.Alone",
  "Ethnicities.American.Indian.and.Alaska.Native.Alone",
  "Employment.Nonemployer.Establishments",
  "Employment.Firms.Women.Owned",
  "Employment.Firms.Men.Owned",
  "Employment.Firms.Minority.Owned",
  "Employment.Firms.Nonminority.Owned",
  "Employment.Firms.Veteran.Owned",
  "Employment.Firms.Nonveteran.Owned",
  "Miscellaneous.Foreign.Born"
)

demographics_df <- demographics_df[, !(names(demographics_df) %in% variables_to_remove)]
```

Abans de procedir, renombrarem la major part de variables per una major comoditat(codi ocultat).

```{r include=FALSE}
demographics_df <- demographics_df %>%
                    rename(
                      pct_more_65y = Age.Percent.65.and.Older,
                      pct_less_18y = Age.Percent.Under.18.Years,
                      pct_high_school  = Education.High.School.or.Higher,
                      pct_asian = Ethnicities.Asian.Alone,
                      pct_black = Ethnicities.Black.Alone,
                      pct_latino = Ethnicities.Hispanic.or.Latino,
                      pct_white = Ethnicities.White.Alone..not.Hispanic.or.Latino,
                      pct_homeownership = Housing.Homeownership.Rate,
                      households = Housing.Households,
                      housing_units = Housing.Housing.Units,
                      median_value_occupied_units = Housing.Median.Value.of.Owner.Occupied.Units,
                      pers_houshold = Housing.Persons.per.Household,
                      median_household_income = Income.Median.Houseold.Income,
                      income_capita = Income.Per.Capita.Income,
                      land_area = Miscellaneous.Land.Area,
                      lang_other_eng = Miscellaneous.Language.Other.than.English.at.Home,
                      living_same_house = Miscellaneous.Living.in.Same.House..1.Years,
                      manufacturers_shipments = Miscellaneous.Manufacturers.Shipments,
                      mean_travel_time_work = Miscellaneous.Mean.Travel.Time.to.Work,
                      pct_female = Miscellaneous.Percent.Female,
                      veterans = Miscellaneous.Veterans,
                      pop_2020 = Population.2020.Population,
                      pop_2010 = Population.2010.Population,
                      pop_square_mile = Population.Population.per.Square.Mile,
                      food_service_sales = Sales.Accommodation.and.Food.Services.Sales,
                      retail_sales = Sales.Retail.Sales,
                      total_firms = Employment.Firms.Total
                    )
```

# 3. Neteja de les dades

## 3.1 Gestió de valors perduts

Un cop tenim el dataset resultant amb el qual treballarem, ara mirarem si el dataset té o no valors perduts. També cal dir que sabem que quan es codifica amb -1 algunes variables demogràfiques significa que no es disposa d'informació.

```{r}
colSums(is.na(demographics_df) | demographics_df == "" | demographics_df == -1)
emptyRows <- which(rowSums(is.na(demographics_df) | demographics_df == "" | demographics_df == -1) > 0)
print(length(emptyRows))
```

Observem com hi ha 1452 comtats que tenen algun valor perdut.

Dels valors perduts per falta d'informació observem dos columnes que destaquen per sobre la resta, que són *manufacturers_shipments* és a dir importacions i *food_service_sales*, és a dir les vendes o l'import venut en alimentació i serveis. Degut al gran nombre de valors perduts (que representen el 38,1% i 19,7% dels casos respectivament), optem per descartar aquestes dues variables. Si bé són dos variables que ens poden ajudar a entendre la bona marxa de l'economia del comtat, considerem que imputar tants valors podria portar a obtenir uns resultats que no s'ajustin del tot a la realitat. A més, ja tenim algunes altres variables per veure la bona marxa de l'economia (com el nombre d'empreses totals o el nombre de vendes minoristes).

```{r}
variables_to_remove <- c(
  "manufacturers_shipments",
  "food_service_sales"
)

demographics_df <- demographics_df[, !(names(demographics_df) %in% variables_to_remove)]
```

Pel que fa a la resta de variables que contenen dades amb falta d'informació, procedirem a realitzar una imputació de valors. En aquest sentit, usant l'algoritme knn buscarem aquells comtats amb els quals comparteixin característiques per tal que els hi assigni el mateix valor que aquestes. D'aquesta manera, si bé estem "predint" el valor, no perdem alguns comtats del nostre dataset.

Per fer la imputació de les variables relatives a l'ètnia (*pct_asian* i *pct_black*), usarem com a variables comparatives per fer la comparació, la resta de variables relatives a l'ètnia, perquè entenem que son comtats que poden tenir distribucions semblants en aquest sentit.

Pel que fa a la variable *mean_travel_time_work*, és a dir el temps mig que es tarda a anar a la feina, usarem la variable *land_area* perquè entenem que en comtats més petits es tardarà menys en arribar que en altres casos. Val a dir que en aquest cas assumim que la gent treballa en el amteix comptat, però veient que només és una observació, entenem que és una assumpció plausible que no afectarà a la globalitat de la mostra.

Pel que fa a la variable *retail_sales* prendrem la variable del total d'empreses, ja que són aquestes les que majoritàriament realitzen les vendes.

Pel que fa a les variables relatives als habitatges, usarem la resta de variables del mateix àmbit per fer la imputació.

Finalment, per la variable *veterans* usarem les variables de majors de 65 anys i població. En aquest sentit veterans són militars retirats (i, en molts casos, ja persones grans). Per tant, les variables de població són les més adequades per fer una imputació del valor perdut.

```{r}
# Passem els -1 d'aquestes variables a NA per poder imputar
vars_to_impute <- c("pct_asian", "pct_black", "mean_travel_time_work",
                    "retail_sales", "veterans", "housing_units",
                    "median_value_occupied_units")

demographics_df <- demographics_df %>%
  mutate(across(all_of(vars_to_impute), ~ ifelse(. == -1.0, NA, .)))



# Realitzem la imputació
demographics_df <-kNN(demographics_df, variable=c("pct_asian", "pct_black"), 
                      dist_var = c("pct_black", "pct_white", "pct_latino", "pct_asian"), 
                      k= 7, metric='gower')

demographics_df <-kNN(demographics_df, variable="mean_travel_time_work", 
                      dist_var = "land_area", 
                      k= 7, metric='gower')

demographics_df <-kNN(demographics_df, variable="retail_sales", 
                      dist_var = "total_firms", 
                      k= 7, metric='gower')

demographics_df <-kNN(demographics_df, 
                      variable=c("housing_units", "median_value_occupied_units"), 
                      dist_var = c("housing_units", "median_value_occupied_units", "pct_homeownership","households", "pers_houshold"), 
                      k= 7, metric='gower')

demographics_df <-kNN(demographics_df, 
                      variable="veterans", 
                      dist_var = c("pop_2010", "pop_2020", "pct_more_65y") , 
                      k= 7, metric='gower')

# Eliminem les columnes creades al fer la imputació
demographics_df <- demographics_df[, -30:-37]

```

Finalment, observem com ara ja no hi ha valors perduts.

```{r}
emptyRows <- which(rowSums(is.na(demographics_df) | demographics_df == "" | demographics_df == -1) > 0)
print(length(emptyRows))
```

## 3.2 Gestió d'outliers

A continuació, es visualitzarà la distribució de les variables i s'empraran tècniques per a detectar valors extrems o outliers. La gestió dels outliers pot variar molt segons l'origen d'aquests, devent ésser eliminats si considerem que són fruit d'un error de transcripció o si no considerem que no representen correctament la població.

En primer lloc, el que hem fet és calcular les estadístiques principals de cada variable del dataset resultant (veure Annex 1) i observem com en tots els casos els valors es troben en el rang plausible / real de les dades. És a dir no hi ha dades negatives en aquelles variables que no n'admeten ni hi ha percentatges inferiors a 0 o superiors a 100 en el cas que la variable estigui en percentatge.

Ara, ens centrarem en els possibles valors extrem. Nombrosa literatura, considera que els valors extrems es troben en aquelles observacions que es troben almenys tres desviacions estàndars allunyades de la mitjana. A l'Annex 2 es troba una taula que calcula aquest interval i el nombre de valors extrems per cada variable.

Ara ho mostrarem alguns histogrames de les variables amb més valors extrems (amb més de 80 valors extrems):

```{r echo=FALSE}

hist_latino <- ggplot(demographics_df, aes(x = pct_latino)) +
  geom_histogram(color = "black", fill = "lightblue", bins = 30) +
  labs(title = "pct_latino",
       x = "pct_latino",
       y = "Frequency")

hist_black <- ggplot(demographics_df, aes(x = pct_black)) +
  geom_histogram(color = "black", fill = "lightpink", bins = 30) +
  labs(title = "pct_black",
       x = "pct_black",
       y = "Frequency")

hist_lang_other_eng <- ggplot(demographics_df, aes(x = lang_other_eng)) +
  geom_histogram(color = "black", fill = "lightgreen", bins = 30) +
  labs(title = "hist_lang_other_eng",
       x = "hist_lang_other_eng",
       y = "Frequency")

box_latino <- ggplot(demographics_df, aes(x = "", y = pct_latino)) +
  geom_boxplot(color = "black", fill = "lightblue") +
  labs(title = "pct_latino") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())

box_black <- ggplot(demographics_df, aes(x = "", y = pct_black)) +
  geom_boxplot(color = "black", fill = "lightpink") +
  labs(title = "pct_black") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())

box_lang_other_eng <- ggplot(demographics_df, aes(x = "", y = lang_other_eng)) +
  geom_boxplot(color = "black", fill = "lightgreen") +
  labs(title = "lang_other_eng") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())

grid.arrange(
  hist_latino,
  hist_black,
  hist_lang_other_eng,
  box_latino,
  box_black,
  box_lang_other_eng,
  ncol = 3
)

```

En aquest casos veiem que la distribució està desviada cap a l'esquerra on hi ha moltes observacions (i això fa que hi hagi més valors extrems). Tot i això, tant per aquestes com per la resta de variables considerem que la font és fiable (prové de l'oficina del cens federal dels EEUU) i considerem els outliers com a vàlids. Per tant, no els treurem.

A més, cal tenir en compte que els EEUU és un país molt extens, amb moltes desigualtats entre zones (a tots els nivells, tant demogràficament com econòmica), amb la qual cosa no trobem estranya la possible presència de valors extrems. Finalment, cal tenir en compte que la mostra és molt gran i que, per cada variable, els valors extrems no representen ni el 2% del total d'observacions de la mostra. Per tant, i reafirmant-nos en l'anterior, no els treurem.

# 4. Anàlisi de les dades

## 4.1 Selecció dels grups

Com hem exposat a l'inici del document, el nostre objectiu és poder determinar quins factors demogràfics i socioecònomics són determinants a l'hora de votar a les eleccions americanes, i concretament veure quins perfils voten al partit Demòcrata (més progressista, dins la idiosincràcia conservadora de la societat americana) i quins al partit Republicà (més conservador).

Per això els grups que seleccionarem seran en funció del partit guanyador a cada comptat, informació capturada a partir de la variable *party*. Per tant un grup el formaran els comtats on han guanyat els demòcrates i l'altre els comtats on han guanyat els republicans.

Per aquest motiu, la passem a tipus factor, juntament amb la variable *state* y *County*.

```{r}
demographics_df$party <-factor(demographics_df$party, labels = c("DEM", "REP"))
demographics_df$State <-as.factor(demographics_df$State)
demographics_df$County <-as.factor(demographics_df$County)
```

També mostrem quants comtats hi ha de cada partit:

```{r}
table(demographics_df$party)
```

Observem com el nombre de comtats on van guanyar els republicans és significativament superior als llocs on van guanyar els demòcrates, malgrat fou Biden (Demòcrata) qui guanyà les eleccions de 2020. Això no és cap anomalia ja que Trump va guanyar en més comtats, si bé la seva densitat de població era força menor.

*Font: <https://www.independent.co.uk/news/world/americas/us-election-2020/how-many-counties-did-biden-win-less-than-trump-fact-check-b1774513.html>*

Sobre aquests grups de dades, aplicarem diferents proves i contrastos:

-   En primer lloc, analitzarem la **correlació entre variables**, centrant-nos sobretot amb la correlació amb la variable *party* i, de forma secundària, amb la variable que captura la diferència de vots entre Trump i Biden. D'aquesta manera esperem poder veure sobre quins factors demogràfics es va fonamentar la victòria demòcrata i què va causar les majors diferències. Farem un gràfic de correlacions de Pearson i, un test de correlació d'Spearmans amb algunes variables.

-   Posteriorment, aplicarem **contrastos d'hipòtesi** per veure quines variables tenen la mateixa mitjana o mediana en tots dos grups i quines no. El test a realitzar dependrà de la normalitat i la homogeneïtat (o no) de la variància.

-   Finalment, farem també una **regressió logística** on la variable dependent sigui el partit i les independents o explicatives la resta de variables.

## 4.2 Comprovació de normalitat i homogeneïtat de la variància

Abans de realitzar els contrasts entre grups, les regressions i les diferents estadístiques ens cal comprovar la normalitat i la homogeneïtat de la variància, perquè els tests a aplicar varien, doncs alguns requereixen normalitat i homoscedesticitat per ser vàlids i no esbiaixats.

### 4.2.1 Normalitat

Pel que fa al test de normalitat, cal dir que una possibilitat seria l'aplicació de l'anomenat **Teorema del Límit Central (TLC)**. Aquest teorema assumeix que per mostres grans (n\>30, com en el nostre cas) la distribució de la mitjana s'aproxima a la normal, independentment de la distribució original de les dades. Tot i això, nosaltres comprovarem la normalitat de les dades usant gràfics Q-Q i el test de Shapiro-Wilk.

També farem el test de Jarque - Bera, tot i que els resultats es mostraran a l'Annex 4.

#### 4.2.1.1 Gràfics Quartil a quartil

Amb els gràfics Quartil - Quartil (o Q-Q) podem observar com es distribueixen les observacions i veure, a ull nu si s'aproximen a la distribució normal (representada per la línia vermella). Com que tenim moltes variables, per no fer un document extremadament extens, mostrarem només els gràfics de les 6 primeres variables, podent-se consultar la totalitat dels gràfics en l'Annex 3.

```{r echo=FALSE, fig.height=3.5}
numerical_vars <- names(demographics_df %>%
                          select(-party, -County, -State))

par(mfrow = c(2, 3)) # Indica el número de gràfics per línia

for (i in seq_along(numerical_vars)) {
  var <- numerical_vars[i]
  qqnorm(demographics_df[[var]], pch = 1, frame = FALSE, main = var)
  qqline(demographics_df[[var]], col = "red", lwd = 2)

  # Stop at the 6th iteration
  if (i == 6) {
    break
  }
}
```

A ull nu considerem que només les variables *pct_more_65y* i *mean_travel_time_work* són suceptibles de tenir una distribució normal atenent als gràfics. Però ho comprovarem amb el test de Shapiro-Wilk, a l'apartat següent.

#### 4.2.1.2 Shapiro-Wilk test

Realitzem el test de Shapiro-Wilk, que treballa amb la hipòtesi nul·la de normalitat de les dades. Per tant, valors de p del test inferiors al nivell de significancia permeten rebutjar la hipòtesi de normalitat de les dades.

```{r}
# Creem una funció per executar el test
shapiro_test_table <- function(dataset) {
  
  results_table <- data.frame(Variable = character(0), P_Value = numeric(0))

  # Loop through each column in the dataset
  for (col in colnames(dataset)) {

    shapiro_test_result <- shapiro.test(dataset[[col]])
    p_value <- shapiro_test_result$p.value
    results_table <- rbind(results_table, data.frame(Variable = col, P_Value = p_value))
  }
  return(results_table)
}

shapiro_table <- demographics_df %>%
  select(-party, -County, -State)
results <- shapiro_test_table(shapiro_table)
kable(results, digits=100, caption="Resultats Shapiro-Wilk test")


```

Observem com els resultats per cada variable ens porten a rebutjar la hipòtesi nul·la de normalitat per totes les dades. Per tant, podem rebutjar la normalitat de les dades. A l'annex 4 trobem el test de Jarque-Bera amb idèntics resultats.

### 4.2.2 Homogeneïtat de la variància

Un cop hem comprovat la no normalitat de les dades, procedirem a comprovar la homogeneitat de la variança, és a dir si la variancia és constant (o no) en els diferents nivells d'un factor (en el nostre cas aquest factor seria la variable *party*, que és el que divideix en grups la mostra). És important comprovar si hi ha homoscedesticitat o heteroscedesticitat perquè algunes regressions i test de contrast assumeixen homoscedesticitat i, en cas de no ser-hi, podria comportar biaixos.

Per comprovar si hi ha homoscedesticitat o no, farem el test de Levene i el test de Fligner - Killeen (que el veurem a l'annex 5). Tots dos testos no requereixen de normalitat en les dades i en tots dos testos la hipòtesis nul·la és la homoscedesticitat de les dades.

```{r}
levene_test_table <- function(dataset, cols) {
  results <- data.frame(variable = character(), p_value = numeric(), stringsAsFactors = FALSE)
  for (col in cols) {

    test_result <-  leveneTest(dataset[[col]], group = dataset$party, center = "median")
    
    p_value <- test_result[1,3]
    
    results <- rbind(results, data.frame(variable = col, p_value = p_value))
  }
  return(results)
}

levene_table <-levene_test_table(demographics_df, numerical_vars)
kable(levene_table, digits=100, caption = "Resultats del test de Levene")
```

Observem com només en les variables *pct_more_65y* i *mean_travel_time_work* es manté la hipòtesis nul·la al nivell del 0.05. En la resta, s'ha de rebutjar i, per tant, podem afirmar que la variancia de la mostra és heteroscedàstica. El test de Fligner-Killeen dona resultats similars.

Cal afirmar que l'heteroscedasticitat és més habitual en dades de secció creuada com en el nostre cas, tal com s'afirma a: <https://ocw.ehu.eus/file.php/23/HETERO.pdf> apunts d'estadística de la Universitat del País Basc.

## 4.3 Aplicació de proves estadístiques

Un cop hem comprovat que les dades no segueixen una distribució normal i que, en general la variància és heteroscedàstica (excepte els casos exposats), procedirem a aplicar diferents proves estadístiques per extreure'n les conclusions.

### 4.3.1 Anàlisi de correlació entre totes les variables

En primer lloc, realitzarem anàlisis de correlacions, tant entre totes les variables com només amb la variable a explicar que és la de *party*. Per fer-ho, primerament codificarem la variable *party* essent 0 quan pren el valor "DEM" (per Demòcrates) i 1 quan pren el valor "REP" (per Republicans).

```{r echo=FALSE, fig.height=3.5}
# Codifiquem la variable party

demographics_df$party_code <- ifelse(demographics_df$party=="DEM", 0, 1)

# Calculem les correlacions amb el mètode de Pearson. 

variables_corr <- names(demographics_df[sapply(demographics_df, is.numeric)])
factors <- demographics_df %>% select(all_of(variables_corr))

correlation_coeficients <- cor(factors, method="pearson")

# Les acabem mostrant en un gràfic
ggcorrplot(correlation_coeficients, hc.order = TRUE, outline.col = "white")+
                    theme(
                    axis.text.x = element_text(size = 8, hjust=1),
                    axis.text.y = element_text(angle = 0, hjust = 1, size = 7)
                    )
```

Del gràfic anterior observem com algunes variables tenen una alta correlació entre elles. Com que el gràfic és poc llegible, ara mostrarem només aquells parells de variables amb un coeficient de Pearson en termes absolut major de 0.5, és a dir aquells parells amb una correlació moderada o alta (codi ocultat):

```{r echo=FALSE, fig.height= 3.5}
#Primer eliminem les correlacions perfectes perquè no es mostrin.
correlation_coeficients[correlation_coeficients==1]<-NA

# Ho convertim en dataframe
correlation_coeficients <- as.data.frame(as.table(correlation_coeficients))

# Eliminem els valors NA que hem creat abans
correlation_coeficients <- na.omit(correlation_coeficients)

correlation_coeficients_05 <- subset(correlation_coeficients, abs(Freq)>=0.5)

correlation_coeficients_05 <- correlation_coeficients_05[order(-abs(correlation_coeficients_05$Freq)),]

correlation_coeficients_05_matrix <- reshape2::acast(correlation_coeficients_05, Var1~Var2, value.var="Freq")

# Ho dibuixem en un gràfic
ggcorrplot(correlation_coeficients_05_matrix, outline.col = "white") +
                    theme(
                    axis.text.x = element_text(size = 8, hjust=1),
                    axis.text.y = element_text(angle = 0, hjust = 1, size = 7)
                    )

```

Observem com hi ha força variables correlacionades, que en els models de regressió poden sobredimensionar algun aspecte i esbiaixar-ne els resultats. S'esmenten a continuació: - Households amb housing units, i alhora amb pop_2020 i pop_2010, i retail_sales totalfirms. Entre elles es correlacionen positivament, ja que el nombre de cases és proporcional amb la població del comptat.

- pct_latino i lang_other_than_eng està molt relacionada per què en general, tots sabran parlar espanyol i anglès.

- median_value_occupied units amb median_household_income. Són dues mètriques que expressen la renda per casa de forma diferent.

- pct_latino, pct_black es correlacionen negativament amb pct_white ja que com més població blanca, menys de les altres.

- pct_high_school amb income_capita es correlacionen positivament, indicant que com més alt el nviell educatiu, millors salaris shi estableixen.

-   median_household_income amb income per capita estàn molt correlacionades.

-   pct_asian està molt relacionada amb moltes variables estranyes, ja que té uns valors majoritàriament propers a 0 en la majoria de comptats.

-   median_value_occupied_units està molt relacionada amb income_capita, ja que com més riquesa, més alt el valor de l'immoble.

-   pct_homeownership i living_same_house tenen una alta correlació.

-   diff_Biden_Trump també està força correlacionat de forma positiva amb variables poblacionals i amb variables en termes absoluts. És lògic perquè a més població, el cens electoral i les diferències podran seran majors en termes absoluts.

Per als models de regressió logística, es treurà **diff_Biden_Trump**, **housing_units**, **pop_2010**, **total_firms**, **retail_sales**, **lang_other_eng**, **pct_less_18y**,**median_value_occupied_units**,**living_same_house**,**pers_household** i **pct_asian**, amb l'objectiu de paliar possibles sobredimensionaments de certa informació.

### 4.3.2 Anàlisi de correlacions amb la variable party

A continuació, farem un breu anàlisi més detallat de les correlacions amb la variable party únicament, ja que ens interessa veure realment aquells factors correlacionats amb la victòria demòcrata i republicana a cada comtat. Calcularem els coeficients de Pearson i la significancia de la correlació.

```{r, fig.height=3}
corr_test <- function(dataset, var1){
  results_table <- data.frame(variable = character(), corr_coeficient = numeric (),
                        p_value = numeric(), stringsAsFactors = FALSE)
  for (col in colnames(dataset)) {
    results <- cor.test(dataset[[col]], dataset[[var1]], method="pearson")
    estimate <- results$estimate
    pvalue <- results$p.value
    results_table <- rbind(results_table, data.frame(Variable = col, 
                                                     corr_coeficient = estimate,
                                                     P_Value = pvalue))
  }
  return(results_table)
}
corr_table <- demographics_df %>%
  select(-party, -County, -State)
results <- corr_test(corr_table, 'party_code')
kable(results, digits=100, caption="Coeficients de Pearson vs variable party i significancia")

# Finalment eliminem la variable party_code perquè no farem més correlacions
demographics_df <- demographics_df[, !names(demographics_df) %in% "party_code"]
```

De la taula anterior podem veure com les variables més correlacionades positivament amb la victòria del partit republicà als comtats són el percentatge de persones de raça blanca i el percentatge de persones propietaries d'una casa ja que la correlació amb la variable és positiva (i recordem que quan pren valor 1 implica victòria republicana), mentre que pels demòcrates ho serien els percentatges de persones de raça afroamericana i asiàtica. Tot i això, són correlacions moderades. Posteriorment a aquestes variables trobem variables de diversos àmbits que caldria estudiar amb més profunditat la relació.

D'altra banda, també observem algunes variables amb una relació molt baix, com *pct_high_school*, *pct_less_18y* o *land_area*.

Finalment, pel que fa a la significancia de les correlacions, totes ho són excepte el percentatge de persones amb estudis.

### 4.3.3. Contrastos d'hipòtesi

Donada la no normalitat de les dades i la variància irregular, s'aplicarà un contrast d'hipòtesi amb un test U de Mann-Whitney. En aquest test no-paramètric, l'estadístic calculat es basa en criteris de jerarquia de les variables segons el grup el qual pertanyen.

En aquest cas la hipòtesi nul·la que es planteja és que no hi ha diferències significants entre les distribucions dels grups, per tant, el rebuig d'aquesta significarà que hi ha diferències significants entre les distribucions de les variables.

S'efectuarà el test per a les variables amb una significància del 0.05.

```{r}

# Apliquem el test a totes les variables
wilcox_results <- lapply(numerical_vars, function(var) wilcox.test(get(var) ~ party, data = demographics_df))

# Extriem els p-valors
p_values <- sapply(wilcox_results, function(result) result$p.value)

# Creem un data frame amb el nom de les variables i els p-valors
wilcox_table <- data.frame(variable = numerical_vars, p_value = p_values, stringsAsFactors = FALSE)

kable(wilcox_table, digits=100, caption="Resultats test U de Mann-Whitney")
```

Els testos evidencien fortes diferències entre les variables dels comptats segons el partit que guanya, doncs l'única hipòtesi nul·la que no es pot rebutjar, és *land_area*. Això implica que pels dos grups hi ha diferències en la mediana de les variables, evidenciant que la demografia i el perfil socioeconòmic que vota republicans i demòcrates és diferent (fins i tot podent evidenciar la presència de racionalitat en la decisió del votant, ja que en general voten en funció de les seves situacions personals i no per mer atzar).

### 4.3.4 Regressió logística

Finalment, farem una regressió logística per predir la variable binària *party*. Aquesta regressió té per objectiu principal veure com afecten les diferents variables a la predicció d'un guanyador per cada comtat. De forma secundària, si aconseguim fer un bon model, també aconsguirem poder predir, a futur, guanyadors d'eleccions a EEUU en base a dades demogràfiques.

Inicialment, es generarà un conjunt *training* i *testing* per fer el model de regressió fent una separació 70-30. A més, les variables numèriques es normalitzaran amb el mètode Min-Max i es treuran aquelles massa correlacionades (veure apartat sobre correlació on s'exposen). Sabem, per com hem fet el factor, que DEM és com si fos 0 i REP és com si fos 1 (a tenir en compte a l'hora d'interpretar els coeficients)

```{r}
set.seed(66)

# Generem els conjunts de train i entrenament
sample <- sample(1:nrow(demographics_df), size=floor(0.7*nrow(demographics_df)))
train  <- demographics_df[sample, ]
test   <- demographics_df[-sample, ]
vars_to_remove <- c("housing_units","households", "pop_2010", "total_firms", "retail_sales", "lang_other_eng", "pct_less_18y","pct_asian","median_household_income","median_value_occupied_units","living_same_house","pers_houshold","County","State", "diff_Biden_Trump")

train <- train[, !(names(demographics_df) %in% vars_to_remove)]
test <- test[, !(names(demographics_df) %in% vars_to_remove)]

numerical_vars <- names(train %>%
                          select(-party))

# Normalitzem les variables
train[, numerical_vars] <- apply(train[, numerical_vars], 2, function(x) (x - min(x)) / (max(x) - min(x)))
test[, numerical_vars] <- apply(test[, numerical_vars], 2, function(x) (x - min(x)) / (max(x) - min(x)))

```

Es comprova que no s'han alterat les proporcions entre les diferents classes al fer la partició.

```{r}
# Proporció de la classe a tota la mostra
prop.table(table(demographics_df$party))

# Proporció de la classe a conjunt train
prop.table(table(train$party))

# Proporció de la classe a conjunt test
prop.table(table(test$party))

```

Procedim a fer el model. Cal dir que hem fet un primer model inicial que es pot consultar a l'Annex 6. Aquest primer model, però, l'hem refinat perquè algunes variables ens apareixien com a no significatives.

```{r}
model2 <-glm(formula = party~.-land_area-mean_travel_time_work -pct_female-pop_square_mile-pct_latino, data=train, family=binomial(link="logit"))
summary(model2)
```

La nova regressió indica que **veterans** no és un predictor òptim, però té rellevància en la probabilitat. Donat que totes les variables són significatives, es dona el model com a definitiu.

A continuació validem el model amb el conjunt test:

```{r}
# Calculem les prediccions amb el conjunt de test
prob <- predict(model2, newdata = test, type = "response")
prediction <- as.factor(ifelse(prob >= 0.5, 1, 0))

# Fem una matriu de confusió per veure quants n'ha classificat bé
levels(prediction) <- levels(test$party)
conf_matrix <- confusionMatrix(test$party, prediction)

print(conf_matrix)
```

El mode de regressió logística ha classificat correctament com a Democrates 86 estats dels 152 que n'hi havia, un 60%. En el cas dels Republicans, 742 de 761, un 97.5%. En els problemes de classificació sempre és més complicat identificar la classe minoritària correctament. També observem unes bones dades de sensibilitat i specificitat (totes dues per sobre del 80%), a més d'una bona precisió del model.

En tot cas, l'objecte principal d'aquest estudi no era evaluar la capacitat predictiva per a decidir quin estat sortirà escollit,sinó entendre quines eren les variables més signficants en aquest decisió. Les agrupem pels pesos:

-Pesos Positius: -**pct_white** -**pct_homeownership** -**veterans**

El percentatge de població blanca, el nombre de veterans i la quantitat de població que posseeix un immoble, augmenten la probabilitat que sortin els Republicans respecte els Demòcrates.

-Pesos Negatius: -**pct_high_school** -**pct_black** -**income_capita** -**pop_2020**

En canvi, l'augment del percentatge d'estudis superiors i de població negra, la renda per càpita i la població total fa que la probabilitat de sortir els Republicans es redueeixi envers la dels Demòcrates.

# 5. Representació dels resultats

Acabats tots els tests estadístics, procedirem a representar els resultats més rellevants de forma gràfica. Aquesta apartat complementa tots els gràfics i taules realitzats en els apartats anteriors. 

Primerament, representarem en un box plot algunes de les mètriques que hem vist que afecten positivament a votar demòcrates o republicans (codi ocultat per major brevetat)

```{r echo=FALSE, fig.height=3.5}
party_colors = c("DEM" = "blue", "REP"="red")
white_box <- ggplot(demographics_df, aes(x = party, y = pct_white, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana pct_white per partit") +
                      ylab("pct_white") +
                      theme_minimal()

black_box <- ggplot(demographics_df, aes(x = party, y = pct_black, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana pct_black per partit") +
                      ylab("pct_black") +
                      theme_minimal()
latin_box <- ggplot(demographics_df, aes(x = party, y = pct_latino, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana pct_latin per partit") +
                      ylab("pct_latin") +
                      theme_minimal()

asian_box <- ggplot(demographics_df, aes(x = party, y = pct_asian, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana pct_asian per partit") +
                      ylab("pct_asian") +
                      theme_minimal()

grid.arrange(white_box, black_box, ncol=2)
```
```{r echo=FALSE, fig.height=3.5}
grid.arrange(latin_box, asian_box, ncol=2)
```
En els boxplots anteriors observem el que ja hem anat explicant anteriorment. En primer lloc, la gran diferència que hi ha en les dades entre estats (cal veure tots els valors extrems o atípics que ens ensenya el gràfic (en aquest cas +- 1.5 RIC). I en segon lloc, com en general, els comtats on han guanyat demòcrates, les medianes d'ètnies no blanques són més altes. En canvi, en els comtats on guanya Trump, la mediana de l'ètnia blanca és molt més gran. Aquest fet es compleix amb totes les ètnies tot i que amb l'ètnia llatina les medianes són més similars.


```{r echo=FALSE, fig.height=2}

income_scatter <- ggplot(demographics_df, aes(x = pop_2020, y = party, color=party)) +
                      geom_point() +
                      scale_color_manual(values = party_colors)+
                      ggtitle("Població dels comtats i guanyador")


grid.arrange(income_scatter, ncol=1)
```
Un altre dels punts que hem vist és que Biden va fonamentar la seva victòria guanyant a comtats (i per tant també estats) amb major població. Trump, en canvi va guanyar en comtats i pobles menys poblats, i en un sistema *winner takes all* perjudica.

```{r echo=FALSE, fig.height=3.5}
party_colors = c("DEM" = "blue", "REP"="red")
income_capita_box <- ggplot(demographics_df, aes(x = party, y = income_capita, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana income_capita") +
                      ylab("income_capita") +
                      theme_minimal()

more65_box <- ggplot(demographics_df, aes(x = party, y = pct_more_65y, fill=party)) +
                      geom_boxplot() +
                      scale_fill_manual(values = party_colors)+
                      ggtitle("Mediana pct_more_65y") +
                      ylab("pct_more_65y") +
                      theme_minimal()

grid.arrange(income_capita_box, more65_box, ncol=2)
```
Els últim punts a visualitzar són com es distribueix el sou per càpita i la població de tercera edat segons el partit. Veiem com en el cas dels demòcrates, són comptats majoritàriament més rics que els Republicans i amb un percentatge d'ancians menor. Això podria indicar que els estats en què la població és més rica,  deu 


A l'annex 7 mostrem altres representacions amb mapes. Potser menys inuitives però força visuals.

# 6. Resolució del problema

Al llarg de la pràctica hem pogut escarbar en els factors electorals dins la societat americana mitjançant la estadística i hem pogut treure conclusions sobre quins són els més crucials. 

-   **Demografia**: Hem confirmat estadísticament que el percentatge de població afroamericana augmenta la probabilitat d'un comtat de votar els Demòcrates. Els comtats amb percentatge de població de la 3a edat, el redueixen ja que es vessen més pels Republicans. Val a dir, que tot i que amb menys força, totes les ètnies no blanques es decanten més per Biden.
En aquesta línia, la presència de veterans està relacionada amb els comtats republicans, per tant indicaria que els retirats de l'exèrcit hi tenen més afiliació. Això pot ser lògic des del punt de vista que els republicans aposten més per la lliure tinença d'armes (i per més militarisme).
-   **Factors econòmics**: Els comtats on la renda per càpita és més alta i on hi ha més propietaris, es redueix la probabilitat de sortir republicans per sobre dels demòcrates. Aquest fet ens ha sorprès una mica ja que els republicans són més conservadors, però es podria deure a la idiosincracia ja conservadora de la societat americana (on llavors les polítiques econòmiques pesen menys) o al fet que també compta quin candidat es presenta. I, en aquest sentit, Trump és més polèmic i genera més divisions ("o l'estimes o l'odies")
-   **Dimensió del comptat**: Hem observat que Biden va fonamentar la seva victòria a les ciutats més grans (amb més població). Això no és un factor sociodemogràfic del votant, però sí que és important de cara a l'estratègia electoral. És a dir, si vols guanyar, cal tenir el vot de les grans metròpolis americanes, més que guanyar a molts petits pobles.


Tot i així, la complexitat de les preferències de vot, no es poden explicar únicament per factors demogràfics o socioeconòmics. En una potència mundial com EE.UU, la intenció de vot es pot veure influenciada pel context geopolític. El paper de les campanyes electorals pot ser decisiu i ara més que mai, es desenvolupen a les xarxes socials, podent influir en la població més que mai. 

Finalment, cal dir que ens hem trobat amb la dificultat de la gran variabilitat de les dades i de l'heteroscedasticitat de la variància que fan que calgui anar amb precaució per extreure certes conclusions. En aquest sentit, hem vist com és altament complex avaluar el comportament electoral d'un país tan gran i tan divers com els EEUU.


# 7. Codi

La gran part del codi es pot consultar en aquest document, si bé el codi complet el podem trobar a: 


<https://github.com/trepi93/Tipologia_i_cicle_de_dades_PR2.git>. 

Sobretot hem ocultat codis per fer gràfics i/o codis per formatejar algunes variables.

# 8. Vídeo

L'enllaç per accedir al vídeo resum és:  

<https://drive.google.com/file/d/1LFZm6g9Oy_-7s1qOkWk5-GIfZ9bZCHmC/view?usp=sharing>. 








| Contribucions             | Signatura |
|---------------------------|-----------|
| Investigació prèvia       | FC, DT    |
| Redacció de les respostes | FC, DT    |
| Desenvolupament del codi  | FC, DT    |
| Participació al vídeo     | FC, DT    |

: Taula de contribucions

------------------------------------------------------------------------

# ANNEX 1: ESTADÍSTIQUES PRINCIPALS DEL DATASET

------------------------------------------------------------------------

```{r}
summary(demographics_df)
```

------------------------------------------------------------------------

# ANNEX 2: UMBRALS DELS VALORS EXTREMS PER VARIABLE I RECOMPTE DE VARIABLES QUE EL SUPEREN

```{r}
extreme_value_threshold_table <- function(dataset) {
  
  numeric_vars <- dataset %>%
    select_if(is.numeric)
  
  # Creem la taula
  result_table <- numeric_vars %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
    group_by(variable) %>%
    summarise(
      Interval = paste(round(mean(value) - 3 * sd(value), 2), round(mean(value) + 3 * sd(value), 2), sep = "-"),
      Count_Outliers = sum(value < mean(value) - 3 * sd(value) | value > mean(value) + 3 * sd(value))
    )
  
  # Imprimir la taula utilitzant kable
  kable(result_table, format = "markdown")
}

extreme_value_threshold_table(demographics_df)
```

------------------------------------------------------------------------

# ANNEX 3: GRÀFICS Q-Q

```{r}
numerical_vars <- names(demographics_df %>%
                          select(-party, -County, -State))

par(mfrow = c(2, 3)) # Indica el número de gràfics per línia

for (i in seq_along(numerical_vars)) {
  var <- numerical_vars[i]
  qqnorm(demographics_df[[var]], pch = 1, frame = FALSE, main = var)
  qqline(demographics_df[[var]], col = "red", lwd = 2)
}
```

------------------------------------------------------------------------

# ANNEX 4: TEST DE JARQUE-BERA

El test de Jarque-Bera comprova si les dades tenen una forma de campana típica d'una distribució normal, essent la hipòtesi nul·la la normalitat de les dades.

Ho fan amb els següents paràmetres:

-   **Skewness** és el valor d'assimetria de la distribució.
-   **Kurtosis** és la mesura dels valors extrems.

```{r}
jarque_test_table <- function(dataset) {

  results <- data.frame(variable = character(), p_value = numeric(), stringsAsFactors = FALSE)

  for (col in colnames(dataset)) {

    test_result <-  jarque.test(dataset[[col]])
    
    p_value <- test_result$p.value
    
    results <- rbind(results, data.frame(variable = col, p_value = p_value))
  }
  
  return(results)
}

jarque_table <- demographics_df %>%
  select(-party, -County, -State)
results <-jarque_test_table(jarque_table)
kable(results, digits=100, caption="Resultats Jarque-Bera test")

```

En aquest cas observem que el test ens permet rebutjar la hipòtesi nul·la per totes les variables. Per tant, podem dir que no hi ha normalitat de les dades.

# ANNEX 5: TEST DE FLIGNER KILLEEN

El test de Fligner-Killeen és un test no paramètric que compara les variancies basant-se en la mitjana.

```{r}

fligner_test_table <- function(dataset, cols) {
  results <- data.frame(variable = character(), p_value = numeric(), stringsAsFactors = FALSE)
  for (col in cols) {
    test_result <-  fligner.test(dataset[[col]], g= dataset$party, center = "median")
    p_value <- test_result$p.value
    
    results <- rbind(results, data.frame(variable = col, p_value = p_value))
  }
  return(results)
}

fligner_table <-fligner_test_table(demographics_df, numerical_vars)
kable(fligner_table, digits=100, caption = "Resultats del test de Fligner-Killeen")
```

# ANNEX 6: MODEL 1 DE REGRESSIÓ LOGÍSTICA

```{r}
model<-glm(formula = party~.,data=train,family=binomial(link="logit"))
summary(model)
```

Del model de regressió logística, podem concloure que hi ha variables que no són bones estimadores del partit escollit al nivell de significancia del 0.01, aquestes són:

-   **land_area**
-   **mean_travel_time_work**
-   **pct_female**
-   **pop_square_mile**
-   **pct_latino**

Les traurem per procedir amb una altre regressió anomenada Model 2 que es pot consultar en el cos de la memòria.

# ANNEX 7: ALTRES REPRESENTACIONS DE LES DADES

Per representar les dades, una manera força visual pot ser amb mapes territorials. En aquest annex en mostrem dos i els comparem amb els resultats electorals per comtat. Cal dir, però, que tot i ser més visuals, poden ser menys intuitius per algú no avesat a l'anàlisi de dades.


```{r}
us_counties <- st_as_sf(map("county", plot = FALSE, fill = TRUE))

state_mapping <- data.frame(State = c("AL", "AR", "AZ", "CA", "CO", "DC", "DE", "FL", "GA", "HI", "IA", "ID", "IL", "IN", "KS", "KY", "LA", "MD", "MI", "MN", "MO", "MS", "MT", "NC", "ND", "NE", "NJ", "NM", "NV", "NY", "OH", "OK", "OR", "PA", "SC", "SD", "TN", "TX", "UT", "VA", "WA", "WI", "WV", "WY"),
                            FullState = c("alabama", "arizona", "arkansas", "california", "colorado", "connecticut", "delaware", "florida", "georgia", "hawaii", "iowa", "idaho", "illinois", "indiana", "kansas", "kentucky", "louisiana", "maryland", "michigan", "minnesota", "missouri", "mississippi", "montana", "north carolina", "north dakota", "nebraska", "new jersey", "new mexico", "nevada", "new york", "ohio", "oklahoma", "oregon", "pennsylvania", "south carolina", "south dakota", "tennessee", "texas", "utah", "virginia", "washington", "wisconsin", "west virginia", "wyoming"))

demographics_df <- merge(demographics_df, state_mapping, by = "State", all.x = TRUE)

demographics_df$County <- tolower(demographics_df$County)
demographics_df$County <- sub("County", "", demographics_df$County, ignore.case = TRUE)
demographics_df$ID <- paste(demographics_df$FullState, demographics_df$County, sep = ",")
us_counties$ID <- gsub("[[:space:],]", "", us_counties$ID)
demographics_df$ID <- gsub("[[:space:],]", "", demographics_df$ID)


maps_df <- merge(us_counties, demographics_df, by = "ID", all = FALSE)

```

```{r}
ggplot() +
  geom_sf(data = maps_df, aes(fill = pct_white), color = "white") +
  scale_fill_gradient(low = "blue", high = "red", name = "Legend") +
  labs(title = "Població blanca per comptat") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_sf(data = maps_df, aes(fill = income_capita), color = "white") +
  scale_fill_gradient(low = "blue", high = "red", name = "Legend") +
  labs(title = "Income per capità per comptat") +
  theme_minimal()
```

```{r}
ggplot() +
  geom_sf(data = maps_df, aes(fill = factor(party)), color = "white") +
  scale_fill_manual(values = c("blue", "red"), name = "Party") +
  labs(title = "Partit per comptats") +
  theme_minimal()

```

Observem les mateixes conclusions que en els gràfics de l'apartat 5, potser de forma més clara en el cas del percentatge de població d'ètnia blanca.
